{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5aebe56",
   "metadata": {},
   "source": [
    "# DYLE+GPT with Aveni data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.9/site-packages (1.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.9/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from openai) (3.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28216813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "from sys import displayhook\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4a41f",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='') # Insert OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94511d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#num_tokens_from_string(str, \"cl100k_base\")\n",
    "\n",
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6da1e7",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/Aveni/all/annotated_demo_08_11.json\", \"r\") as demo: \n",
    "     demo_queries = json.load(demo)\n",
    "\n",
    "# make lists with queries\n",
    "topic_list = []\n",
    "general_query_list = []\n",
    "specific_query_list = []\n",
    "\n",
    "for i in demo_queries['topic_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"topic\":\n",
    "              topic_list.append(val)\n",
    "for i in demo_queries['general_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              general_query_list.append(val)\n",
    "for i in demo_queries['specific_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              specific_query_list.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved topk\n",
    "with open('../Data/AllQMSum_AVENI_DYLE_test.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_and_context = {}\n",
    "queries = general_query_list + specific_query_list\n",
    "dyle_answers = []\n",
    "\n",
    "word_tok_text = word_tokenize(text)\n",
    "topk = []\n",
    "for i in range(len(word_tok_text)):\n",
    "    this_topk = []\n",
    "    this_ans = []\n",
    "    if word_tok_text[i] == 'topk':     \n",
    "        i = i+2\n",
    "        while word_tok_text[i] != '--':\n",
    "            this_topk.append(word_tok_text[i])\n",
    "            i = i+1\n",
    "        this_topk = ' '.join(this_topk)\n",
    "        topk.append(this_topk)\n",
    "        \n",
    "    if word_tok_text[i] == 'Pred':\n",
    "        i = i+2\n",
    "        while word_tok_text[i] != '--':\n",
    "            this_ans.append(word_tok_text[i])\n",
    "            i = i+1\n",
    "        this_ans = ' '.join(this_ans)\n",
    "        dyle_answers.append(this_ans)\n",
    "        \n",
    "        \n",
    "for i in range(len(queries)):\n",
    "    queries_and_context[queries[i]] = topk[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778369b5",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0314c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(topk: str) -> str:\n",
    "    info = f\"\"\"You're the assistant for a financial advisor. Use the below retreievd content from a meeting transcript to answer all questions. If the answer cannot be found, write \"n/a\"\n",
    "\n",
    "retrieved content:\n",
    "\\\"\\\"\\\"\n",
    "{topk}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "\"\"\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str, topk: str,\n",
    "    print_message: bool = False) -> str:\n",
    "  #  if print_message:\n",
    "   #     print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": get_info(topk)},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_list = []\n",
    "for question, topk in queries_and_context.items():\n",
    "    response = ask(question, topk)\n",
    "    hyp_list.append(tokenize(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198049b9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48571ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Aveni/all/annotated_demo_08_11.json') as refs:\n",
    "    refs_data = json.load(refs)\n",
    "\n",
    "ref_list = []\n",
    "for i in refs_data['general_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))\n",
    "for i in refs_data['specific_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa257df",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = []\n",
    "for i in range(len(hyp_list)):\n",
    "    data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "pprint(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dyle_gpt_output.txt', 'w') as f:\n",
    "    for line in data:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6dd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyp': 'the main reason for seeking advice is because the individual is not an expert in financial planning , particularly when it comes to pensions . they have a large workplace pension and want to ensure they will have enough money for retirement . they were referred to acme limited by a friend who spoke highly of the company .', 'ref': 'the client is seeking advice because of his lack of expertise in financial planning . he wants to ensure that he will have enough money for retirement , and he chose acme limited because his friend carol recommended the company . the client values the peace of mind that comes from consulting with a knowlegeable advisor .'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393f3a5",
   "metadata": {},
   "source": [
    "Token number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hi . sorry , sorry , the paceman . and when is retirement for you ? no , '\n",
      " \"just me on my own . okay , great . so the questions have n't changed , so \"\n",
      " 'hopefully it all comes flooding back to you , mr. smith . um , so just to '\n",
      " 'remind you , try to get your investment portfolio out of your head . okay . '\n",
      " 'and just try to think about how you personally feel at this moment in time '\n",
      " 'between risk and reward . okay . so question one , how would you describe '\n",
      " 'your typical attitude , uh , and making important financial decisions ? '\n",
      " \"would you say you 're very adventurous , fairly adventurous , balance of \"\n",
      " 'adventure and caution ? fairly careful or very careful ? yeah , that sounds '\n",
      " \"good . okay , cool . sure , that sounds good . that 's it . yeah , that , \"\n",
      " 'that sounds like a good summary of , of what i was trying to say , okay . '\n",
      " 'yeah , sounds good . yes , so i inherited that property from my late father '\n",
      " '. good , good way to view life really . um , and how would you rate your own '\n",
      " 'willingness to take financial risks ? a very low risk taker , a low risk '\n",
      " 'taker , moderate high , or very high risk taker ? yeah , no problem at all . '\n",
      " \"yep . yeah , i 'm fine with that . no , not just now . no , that 's been \"\n",
      " \"invested since 2008. yeah , i do n't need any more income at the moment . i \"\n",
      " 'just want the funds to keep greg . the 25th of november , 1999. okay , good '\n",
      " \". so your second property , the one that 's currently rented out , any plans \"\n",
      " 'for that property ? thank you . and just confirmed your address and postcode '\n",
      " '. no , i still want my estate to be distributed in that way . okay , sounds '\n",
      " 'good .')\n"
     ]
    }
   ],
   "source": [
    "pprint(queries_and_context[queries[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ded736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average retrieved tokens DYLE:  814.45\n",
      "average generated tokens GPT:  63.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retrieved_tok = []\n",
    "gen_tok = []\n",
    "i = 0\n",
    "for question, topk in queries_and_context.items():\n",
    "    retrieved_tok.append(num_tokens_from_string(topk, \"cl100k_base\"))\n",
    "    gen_tok.append(num_tokens_from_string(hyp_list[i], \"cl100k_base\"))\n",
    "    i += 1\n",
    "print('average retrieved tokens DYLE: ', np.mean(retrieved_tok))\n",
    "print('average generated tokens GPT: ', np.mean(gen_tok))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b946a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average generated tokens DYLE:  110.825\n"
     ]
    }
   ],
   "source": [
    "#average generated tokens DYLE\n",
    "print('average generated tokens DYLE: ', np.mean([num_tokens_from_string(i, \"cl100k_base\") for i in dyle_answers]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
