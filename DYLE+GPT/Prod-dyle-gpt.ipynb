{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5aebe56",
   "metadata": {},
   "source": [
    "# DYLE+GPT with Product test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.9/site-packages (1.13.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.9/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from openai) (3.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from rouge import Rouge\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sys import displayhook\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import os\n",
    "from rouge import Rouge\n",
    "from pprint import pprint\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534641e",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='') # Insert OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "# For openai\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#num_tokens_from_string(str, \"cl100k_base\")\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e1da6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make lists with queries\n",
    "topic_list = []\n",
    "queries = []\n",
    "ref_list = []\n",
    "ref_and_queries = {}\n",
    "\n",
    "for file in os.listdir('../Data/QMSum/data/Product/test/'): \n",
    "    if file != '.ipynb_checkpoints':\n",
    "        f = os.path.join('./Data/prod', file)\n",
    "        with open(f, \"r\") as f:\n",
    "             data = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        for i in data['topic_list']:\n",
    "            for key, val in i.items():\n",
    "                if key == \"topic\":\n",
    "                    topic_list.append(val)\n",
    "        for i in data['general_query_list']:\n",
    "            for key, val in i.items():\n",
    "                if key == \"query\":\n",
    "                    queries.append(val)\n",
    "                if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "        for i in data['specific_query_list']:\n",
    "            for key, val in i.items():\n",
    "                if key == \"query\":\n",
    "                    queries.append(val)\n",
    "                if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "                    \n",
    "                    \n",
    "for i in range(0, len(queries)):\n",
    "    ref_and_queries[ref_list[i]] = queries[i]\n",
    "    \n",
    "    \n",
    "assert(len(queries) == len(ref_list))\n",
    "assert(len(queries) == 151)\n",
    "assert(len(ref_list) == 151)\n",
    "assert(len(ref_and_queries) == len(ref_list))\n",
    "assert(len(ref_and_queries) == len(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bebe6",
   "metadata": {},
   "source": [
    "Getting the retrieved content from DYLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved topk\n",
    "with open('../Data/Product_dyle_output.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_and_queries = {}\n",
    "dyle_answers = []\n",
    "ref_list_out = []\n",
    "\n",
    "word_tok_text = word_tokenize(clean_data(text))\n",
    "topk = []\n",
    "for i in range(len(word_tok_text)):\n",
    "    this_topk = []\n",
    "    this_ans = []\n",
    "    this_ref = []\n",
    "    if word_tok_text[i] == 'Pred':\n",
    "        i = i+2\n",
    "        while word_tok_text[i] != '--':\n",
    "            this_ans.append(word_tok_text[i])\n",
    "            i = i+1\n",
    "        this_ans = ' '.join(this_ans)\n",
    "        dyle_answers.append(this_ans)\n",
    "        \n",
    "    if word_tok_text[i] == 'topk':     \n",
    "        i = i+2\n",
    "        while word_tok_text[i] != '--':\n",
    "            this_topk.append(word_tok_text[i])\n",
    "            i = i+1\n",
    "        this_topk = ' '.join(this_topk)\n",
    "        topk.append(this_topk)\n",
    "        \n",
    "    if word_tok_text[i] == 'Ref':\n",
    "        i = i+2\n",
    "        while word_tok_text[i] != '--':\n",
    "            this_ref.append(word_tok_text[i])\n",
    "            i = i+1\n",
    "        this_ref = ' '.join(this_ref)\n",
    "        ref_list_out.append(this_ref)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for ref in ref_list_out:\n",
    "    for ref, query in ref_and_queries.items():\n",
    "        if ref == ref:\n",
    "            queries[i] == query\n",
    "    i += 1\n",
    "           \n",
    "for i in range(len(queries)):\n",
    "    \n",
    "    context_and_queries[clean_data(topk[i])] = queries[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053806fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "print(len(context_and_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227bfea8",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0314c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(topk: str) -> str:\n",
    "    info = f\"\"\"Use the below content from a meeting transcript to answer all questions.\"\n",
    "\n",
    "retrieved content:\n",
    "\\\"\\\"\\\"\n",
    "{topk}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "\"\"\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str, topk: str,\n",
    "    print_message: bool = False) -> str:\n",
    "   # if print_message:\n",
    "    #    print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": get_info(topk)},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "hyp_list = []\n",
    "for topk, question in context_and_queries.items():\n",
    "    response = ask(question, topk)\n",
    "    hyp_list.append(tokenize(response))\n",
    "    \n",
    "print(len(hyp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198049b9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa257df",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "{'rouge-1': {'f': 0.22736853110443908,\n",
      "             'p': 0.27615508173700654,\n",
      "             'r': 0.22481599144401837},\n",
      " 'rouge-2': {'f': 0.05995408940415393,\n",
      "             'p': 0.07807180971984276,\n",
      "             'r': 0.05932521073651497},\n",
      " 'rouge-l': {'f': 0.19313297371451388,\n",
      "             'p': 0.23414034366997105,\n",
      "             'r': 0.1917696265820316}}\n"
     ]
    }
   ],
   "source": [
    "print(len(hyp_list))\n",
    "\n",
    "data = []\n",
    "for i in range(len(hyp_list)):\n",
    "    data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "pprint(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dyle_gpt_prod_output.txt', 'w') as f:\n",
    "    for line in data:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6dd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did the group think the remote control was easy to use when discussing evaluation criteria of the remote control?\n",
      "{'hyp': 'there is no specific mention in the content about the group discussing the evaluation criteria of the remote control or their thoughts on its ease of use .', 'ref': 'user interface believed that voice recognition was hard to learn while industrial designer argued that the remote control had two parts and everyone could use the basic part . he also pointed out that an advanced user would like to explore additional functions .'}\n"
     ]
    }
   ],
   "source": [
    "print(queries[2])\n",
    "print(data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393f3a5",
   "metadata": {},
   "source": [
    "Token number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ded736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average retrieved tokens DYLE:  661.8278145695364\n",
      "average generated tokens GPT:  76.23841059602648\n"
     ]
    }
   ],
   "source": [
    "\n",
    "retrieved_tok = []\n",
    "gen_tok = []\n",
    "i = 0\n",
    "for topk, question in context_and_queries.items():\n",
    "    retrieved_tok.append(num_tokens_from_string(topk, \"cl100k_base\"))\n",
    "    gen_tok.append(num_tokens_from_string(hyp_list[i], \"cl100k_base\"))\n",
    "    i += 1\n",
    "print('average retrieved tokens DYLE: ', np.mean(retrieved_tok))\n",
    "print('average generated tokens GPT: ', np.mean(gen_tok))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b946a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average generated tokens DYLE:  105.57615894039735\n"
     ]
    }
   ],
   "source": [
    "#average generated tokens DYLE\n",
    "print('average generated tokens DYLE: ', np.mean([num_tokens_from_string(i, \"cl100k_base\") for i in dyle_answers]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
