{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1631fccf",
   "metadata": {},
   "source": [
    "# LangChain+GPT with Aveni data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63464278",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet  langchain langchain-openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jq\n",
    "!pip install langchain-community==0.0.24 # more recent versions throw errors\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.memory import ConversationBufferWindowMemory\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "from rouge import Rouge\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe089ca",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#num_tokens_from_string(str, \"cl100k_base\")\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d49b5",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only meeting content\n",
    "with open(\"../Data/Aveni/all/annotated_demo_08_11.json\", \"r\") as f:\n",
    "     transcript = json.load(f)\n",
    "f.close()\n",
    "\n",
    "text = []\n",
    "for turn in transcript['meeting_transcripts']:\n",
    "    cur_turn = turn['speaker'].lower() + ': '\n",
    "    text.append(clean_data(' '.join(word_tokenize(cur_turn + turn['content'].lower()))))\n",
    "\n",
    "# print(text)\n",
    "\n",
    "\n",
    "with open(\"../Data/Aveni/all/annotated_demo_08_11.json\", \"r\") as demo:\n",
    "     demo_queries = json.load(demo)\n",
    "\n",
    "# make lists with queries\n",
    "topic_list = []\n",
    "general_query_list = []\n",
    "specific_query_list = []\n",
    "\n",
    "for i in demo_queries['topic_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"topic\":\n",
    "              topic_list.append(val)\n",
    "for i in demo_queries['general_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              general_query_list.append(val)\n",
    "for i in demo_queries['specific_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              specific_query_list.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dda214",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984149aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split meeting transcript\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.create_documents(text)\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Embed split documents (One embedding per turn in conversation)\n",
    "embeddings=OpenAIEmbeddings(openai_api_key = '') # Insert OpenAI API key\n",
    "embedding_list = embeddings.embed_documents([document.page_content for document in split_documents])\n",
    " \n",
    "print(f\"You have {len(embedding_list)} embeddings\")\n",
    "print(f\"Here's a sample of one: {embedding_list[0][:3]}...\")\n",
    "\n",
    "# Store embeddings in FAISS vectorstore\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Use vectorstore as retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Config model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.0, openai_api_key = '') # Insert OpenAI API key\n",
    "\n",
    "# Create prompt template\n",
    "template = \"\"\"You're the assistant for a financial advisor. Use the below context from a meeting transcript to answer all questions. If the answer cannot be found, write \"n/a\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create LangChain chain\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e14242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "chain.invoke({\"question\": \"is the client risk adverse?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab84a71",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_answers = []\n",
    "retrieved = []\n",
    "for question in general_query_list:\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    question_sources = ''\n",
    "    for doc in docs:\n",
    "        question_sources+=(''.join(doc.page_content))\n",
    "    retrieved.append(question_sources)\n",
    "    general_answers.append(tokenize(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01605ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_answers = []\n",
    "for question in specific_query_list:\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    question_sources = ''\n",
    "    for doc in docs:\n",
    "        question_sources+=(''.join(doc.page_content))\n",
    "    retrieved.append(question_sources)\n",
    "    specific_answers.append(tokenize(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print((retrieved[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a2aad",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be10d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Aveni/all/annotated_demo_08_11.json') as refs:\n",
    "    refs_data = json.load(refs)\n",
    "\n",
    "ref_list = []\n",
    "for i in refs_data['general_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))\n",
    "for i in refs_data['specific_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))\n",
    "                \n",
    "hyp_list = general_answers+specific_answers\n",
    "assert len(hyp_list) == len(ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cde4e5",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07646433",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(hyp_list)):\n",
    "    data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "pprint(avg_scores)\n",
    "\n",
    "\n",
    "# Write prediction and reference to file for qualitative evaluation\n",
    "f = open(\"output.txt\", \"w\")\n",
    "with open('output.txt', 'w') as f:\n",
    "    for line in data:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4005da",
   "metadata": {},
   "source": [
    "Retriever evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ec2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_retrieved = [tokenize(k) for k in retrieved]\n",
    "print(tok_retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(ref_list)):\n",
    "    data.append({'hyp': tok_retrieved[i], 'ref': ref_list[i]})\n",
    "    \n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "pprint(avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590cd95c",
   "metadata": {},
   "source": [
    "Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_tok = []\n",
    "gen_tok = []\n",
    "i = 0\n",
    "for topk in retrieved:\n",
    "    retrieved_tok.append(num_tokens_from_string(topk, \"cl100k_base\"))\n",
    "    gen_tok.append(num_tokens_from_string(hyp_list[i], \"cl100k_base\"))\n",
    "    i += 1\n",
    "print('average retrieved tokens Langchain: ', np.mean(retrieved_tok))\n",
    "print('average generated tokens GPT: ', np.mean(gen_tok))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
