{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1631fccf",
   "metadata": {},
   "source": [
    "# LangChain+GPT with Product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63464278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31b3579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jq in /opt/conda/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Collecting langchain-community==0.0.24\n",
      "  Using cached langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (0.5.14)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (1.23.5)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (0.1.28)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (1.4.41)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (0.1.14)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (3.8.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.9/site-packages (from langchain-community==0.0.24) (2.28.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.24) (22.1.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.24) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.24) (3.20.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (1.10.12)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (23.2)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (3.6.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.24) (3.9.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.24) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.24) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.24) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.24) (1.1.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.26->langchain-community==0.0.24) (4.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.24) (1.0.0)\n",
      "Installing collected packages: langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.25\n",
      "    Uninstalling langchain-community-0.0.25:\n",
      "      Successfully uninstalled langchain-community-0.0.25\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.10 requires langchain-community<0.1,>=0.0.25, but you have langchain-community 0.0.24 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-community-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install jq\n",
    "!pip install rouge\n",
    "!pip install langchain-community==0.0.24 # more recent versions throw errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5298a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.memory import ConversationBufferWindowMemory\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f74f8",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e56134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "# For openai\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#num_tokens_from_string(str, \"cl100k_base\")\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d63b14",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21389978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file, path):\n",
    "    f = os.path.join(path, file)\n",
    "    with open(f, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    text = []\n",
    "    for turn in data['meeting_transcripts']:\n",
    "        cur_turn = turn['speaker'].lower() + ': '\n",
    "        text.append(clean_data(' '.join(word_tokenize(cur_turn + turn['content'].lower()))))\n",
    "\n",
    "    # make lists with queries\n",
    "    topic_list = []\n",
    "    general_query_list = []\n",
    "    specific_query_list = []\n",
    "    ref_list = []\n",
    "\n",
    "    for i in data['topic_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"topic\":\n",
    "                    topic_list.append(val)\n",
    "    for i in data['general_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"query\":\n",
    "                    general_query_list.append(val)\n",
    "            if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "    for i in data['specific_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"query\":\n",
    "                    specific_query_list.append(val)\n",
    "            if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "\n",
    "    return text, topic_list, general_query_list, specific_query_list, ref_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e42e7",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(text):\n",
    "    # Split meeting transcript\n",
    "    text_splitter = RecursiveCharacterTextSplitter()\n",
    "    documents = text_splitter.create_documents(text)\n",
    "    split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Embed split documents (One embedding per turn in conversation)\n",
    "    embeddings=OpenAIEmbeddings(openai_api_key = '') # Insert OpenAI API key\n",
    "    embedding_list = embeddings.embed_documents([document.page_content for document in split_documents])\n",
    "    \n",
    "    print(f\"You have {len(embedding_list)} embeddings\")\n",
    "    print(f\"Here's a sample of one: {embedding_list[0][:3]}...\")\n",
    "\n",
    "    # Store embeddings in FAISS vectorstore\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    # Use vectorstore as retriever\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})\n",
    "\n",
    "    # Config model\n",
    "    model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.0, openai_api_key = '') # Insert OpenAI API key\n",
    "\n",
    "    # Create prompt template\n",
    "    template = \"\"\"You're the assistant during the process of designing a new remote control. Use the below context from a meeting transcript to answer all questions.\"\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Create LangChain chain\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "            \"question\": itemgetter(\"question\")\n",
    "        }\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain, retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad98a8",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores = []\n",
    "r_scores = []\n",
    "n_tok_ret = []\n",
    "n_tok_gen = []\n",
    "all_hyps_and_refs = []\n",
    "PATH = '../Data/QMSum/data/Product/test/' #change /test to /all to run on entire dataset\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if file.endswith('.json'):\n",
    "        text, topic_list, general_query_list, specific_query_list, ref_list = process_file(file, PATH)\n",
    "\n",
    "        chain, retriever = create_model(text)\n",
    "\n",
    "        print(chain.invoke({\"question\": \"What did the group discuss about remote control style and design optimization?\"}))\n",
    "\n",
    "        general_answers = []\n",
    "        retrieved = []\n",
    "        \n",
    "        for question in general_query_list:\n",
    "            response = chain.invoke({\"question\": question})\n",
    "            docs = retriever.get_relevant_documents(question)\n",
    "            question_sources = ''\n",
    "            for doc in docs:\n",
    "                question_sources+=(''.join(doc.page_content))\n",
    "            retrieved.append(question_sources)\n",
    "            general_answers.append(tokenize(response))\n",
    "\n",
    "        specific_answers = []\n",
    "        for question in specific_query_list:\n",
    "            response = chain.invoke({\"question\": question})\n",
    "            docs = retriever.get_relevant_documents(question)\n",
    "            question_sources = ''\n",
    "            for doc in docs:\n",
    "                question_sources+=(''.join(doc.page_content))\n",
    "            retrieved.append(question_sources)\n",
    "            specific_answers.append(tokenize(response))\n",
    "\n",
    "        hyp_list = general_answers+specific_answers\n",
    "        assert len(hyp_list) == len(ref_list)\n",
    "\n",
    "        # Evaluating the outputs for each meeting transcript \n",
    "        # Summary evaluation\n",
    "        data = []\n",
    "        for i in range(len(hyp_list)):\n",
    "            data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "            all_hyps_and_refs.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "        hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "        rouge = Rouge()\n",
    "\n",
    "        scores = rouge.get_scores(hyps, refs)\n",
    "        # or\n",
    "        avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "        s_scores += scores\n",
    "\n",
    "        # Retriever evaluation\n",
    "        tok_retrieved = [tokenize(k) for k in retrieved]\n",
    "        data = []\n",
    "        for i in range(len(ref_list)):\n",
    "            data.append({'hyp': tok_retrieved[i], 'ref': ref_list[i]})\n",
    "\n",
    "        hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "        rouge = Rouge()\n",
    "\n",
    "        scores = rouge.get_scores(hyps, refs)\n",
    "        # or\n",
    "        avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "        r_scores += scores\n",
    "\n",
    "        # Number of tokens\n",
    "        retrieved_tok = []\n",
    "        gen_tok = []\n",
    "        i = 0\n",
    "        for topk in retrieved:\n",
    "            retrieved_tok.append(num_tokens_from_string(topk, \"cl100k_base\"))\n",
    "            gen_tok.append(num_tokens_from_string(hyp_list[i], \"cl100k_base\"))\n",
    "            i += 1\n",
    "\n",
    "        n_tok_ret.append(np.mean(retrieved_tok))\n",
    "        n_tok_gen.append(np.mean(gen_tok))\n",
    "        \n",
    "f = open(\"prod_langchain_output.txt\", \"w\")\n",
    "with open('prod_langchain_output.txt', 'w') as f:\n",
    "    for line in all_hyps_and_refs:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd9b63",
   "metadata": {},
   "source": [
    "## Evaluation for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e217ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_mean(dict_list):\n",
    "    mean_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        mean_dict[key] = sum(d[key] for d in dict_list) / len(dict_list)\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29be314",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14d9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1 summariser\n",
      "{'f': 0.2948041544738696, 'p': 0.3493053466510047, 'r': 0.29319319530631666}\n",
      "rouge-2\n",
      "{'f': 0.0900664476607133, 'p': 0.10704261057110534, 'r': 0.09570058151497235}\n",
      "rouge-l\n",
      "{'f': 0.25260941313943397, 'p': 0.2970537819587526, 'r': 0.25299690129493096}\n"
     ]
    }
   ],
   "source": [
    "#get averages for evaluation\n",
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_l = []\n",
    "for d in s_scores:\n",
    "    rouge_1.append(d['rouge-1'])\n",
    "    rouge_2.append(d['rouge-2'])\n",
    "    rouge_l.append(d['rouge-l'])\n",
    "    \n",
    "\n",
    "print('rouge-1 summariser')\n",
    "pprint(dict_mean(rouge_1))\n",
    "print('rouge-2')\n",
    "pprint(dict_mean(rouge_2))\n",
    "print('rouge-l')\n",
    "pprint(dict_mean(rouge_l))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0d73b",
   "metadata": {},
   "source": [
    "Retriever evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55bbea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1 retriever\n",
      "{'f': 0.22198814856725982, 'p': 0.17029521280968482, 'r': 0.46547392144334776}\n",
      "rouge-2\n",
      "{'f': 0.04205691349921885, 'p': 0.02993006017291858, 'r': 0.13952224705720365}\n",
      "rouge-l\n",
      "{'f': 0.2023090612778814, 'p': 0.1552680683953529, 'r': 0.42675458413629785}\n"
     ]
    }
   ],
   "source": [
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_l = []\n",
    "for d in r_scores:\n",
    "    rouge_1.append(d['rouge-1'])\n",
    "    rouge_2.append(d['rouge-2'])\n",
    "    rouge_l.append(d['rouge-l'])\n",
    "    \n",
    "\n",
    "print('rouge-1 retriever')\n",
    "pprint(dict_mean(rouge_1))\n",
    "print('rouge-2')\n",
    "pprint(dict_mean(rouge_2))\n",
    "print('rouge-l')\n",
    "pprint(dict_mean(rouge_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c687763",
   "metadata": {},
   "source": [
    "Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52669a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average retrieved tokens:  513.2662408424909\n",
      "average generated tokens:  70.37067307692308\n"
     ]
    }
   ],
   "source": [
    "print('average retrieved tokens: ', np.mean(n_tok_ret))\n",
    "print('average generated tokens: ', np.mean(n_tok_gen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
