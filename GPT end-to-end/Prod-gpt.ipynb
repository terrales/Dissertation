{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e020fd94",
   "metadata": {},
   "source": [
    "# GPT end-to-end with Product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.9/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.9/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from openai) (3.6.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed openai-1.13.3\n",
      "Requirement already satisfied: jq in /opt/conda/lib/python3.9/site-packages (1.5.0)\n",
      "Collecting rouge\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install jq\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657d75cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from rouge import Rouge\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import os\n",
    "from sys import displayhook\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5386aa",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74f5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "# For openai\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#num_tokens_from_string(str, \"cl100k_base\")\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75542541",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='') # Insert OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba492f41",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888478bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file, path):\n",
    "    f = os.path.join(path, file)\n",
    "    with open(f, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    text = []\n",
    "    for turn in data['meeting_transcripts']:\n",
    "        cur_turn = turn['speaker'].lower() + ': '\n",
    "        text.append(clean_data(' '.join(word_tokenize(cur_turn + turn['content'].lower()))))\n",
    "\n",
    "    # make lists with queries\n",
    "    topic_list = []\n",
    "    general_query_list = []\n",
    "    specific_query_list = []\n",
    "    ref_list = []\n",
    "\n",
    "    for i in data['topic_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"topic\":\n",
    "                    topic_list.append(val)\n",
    "    for i in data['general_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"query\":\n",
    "                    general_query_list.append(val)\n",
    "            if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "    for i in data['specific_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"query\":\n",
    "                    specific_query_list.append(val)\n",
    "            if key == \"answer\": \n",
    "                    ref_list.append(tokenize(val))\n",
    "\n",
    "    return text, topic_list, general_query_list, specific_query_list, ref_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85bf9f",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac21a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str, info,\n",
    "    print_message: bool = False) -> str:\n",
    "    #message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "   # if print_message:\n",
    "    #    print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": info},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7a4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scores = []\n",
    "r_scores = []\n",
    "meeting_tok = []\n",
    "n_tok_gen = []\n",
    "all_hyp_ref = []\n",
    "PATH = '../Data/QMSum/data/Product/test/' #change /test to /all to run on entire dataset\n",
    "\n",
    "for file in os.listdir(PATH):\n",
    "    if file != '.ipynb_checkpoints':\n",
    "        text, topic_list, general_query_list, specific_query_list, ref_list = process_file(file, PATH)\n",
    "\n",
    "\n",
    "        info = f\"\"\"You're the assistant during the process of designing a new remote control. Use the below meeting transcript to answer all questions. If the answer cannot be found, write \"n/a\"\n",
    "\n",
    "        Transcript:\n",
    "        \\\"\\\"\\\"\n",
    "        {text}\n",
    "        \\\"\\\"\\\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        general_answers = []\n",
    "        for question in general_query_list:\n",
    "            response = ask(question, info)\n",
    "            general_answers.append(tokenize(response))\n",
    "\n",
    "        specific_answers = []\n",
    "        for question in specific_query_list:\n",
    "            response = ask(question, info)\n",
    "            specific_answers.append(tokenize(response))\n",
    "\n",
    "\n",
    "        hyp_list = general_answers+specific_answers\n",
    "        assert len(hyp_list) == len(ref_list)\n",
    "\n",
    "        # Evaluating the outputs for each meeting transcript \n",
    "        # Summary evaluation\n",
    "        data = []\n",
    "        for i in range(len(hyp_list)):\n",
    "            data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "        hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "        rouge = Rouge()\n",
    "\n",
    "        scores = rouge.get_scores(hyps, refs)\n",
    "        # or\n",
    "        avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "        s_scores += scores\n",
    "        \n",
    "        for line in data:\n",
    "            all_hyp_ref.append(line)\n",
    "\n",
    "        # Number of tokens in the context\n",
    "        meeting_tok.append(num_tokens_from_string(info, \"cl100k_base\"))\n",
    "\n",
    "        # Number of tokens generated\n",
    "        gen_tok = []\n",
    "        for hyp in hyp_list:\n",
    "            gen_tok.append(num_tokens_from_string(hyp, \"cl100k_base\"))\n",
    "\n",
    "        n_tok_gen.append(np.mean(gen_tok))\n",
    "\n",
    "f = open(\"prod_gpt_output.txt\", \"w\")\n",
    "with open('prod_gpt_output.txt', 'w') as f:\n",
    "    for line in all_hyp_ref:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce22bc7",
   "metadata": {},
   "source": [
    "## Evaluation for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3514d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_mean(dict_list):\n",
    "    mean_dict = {}\n",
    "    for key in dict_list[0].keys():\n",
    "        mean_dict[key] = sum(d[key] for d in dict_list) / len(dict_list)\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b9888",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba1fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge-1 summariser\n",
      "{'f': 0.313803413591332, 'p': 0.3380606402683946, 'r': 0.33276109428684886}\n",
      "rouge-2\n",
      "{'f': 0.09844713702081342, 'p': 0.10663581083659154, 'r': 0.11016142824236123}\n",
      "rouge-l\n",
      "{'f': 0.2670658366640899, 'p': 0.28606474442514934, 'r': 0.28501079814009156}\n"
     ]
    }
   ],
   "source": [
    "#get averages for evaluation\n",
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_l = []\n",
    "for d in s_scores:\n",
    "    rouge_1.append(d['rouge-1'])\n",
    "    rouge_2.append(d['rouge-2'])\n",
    "    rouge_l.append(d['rouge-l'])\n",
    "    \n",
    "\n",
    "print('rouge-1 summariser')\n",
    "pprint(dict_mean(rouge_1))\n",
    "print('rouge-2')\n",
    "pprint(dict_mean(rouge_2))\n",
    "print('rouge-l')\n",
    "pprint(dict_mean(rouge_l))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359a0b1",
   "metadata": {},
   "source": [
    "Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c142b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average generated tokens:  89.77298534798534\n",
      "average tokens in info (instructions + transcript):  9366.5\n"
     ]
    }
   ],
   "source": [
    "#print('average retrieved tokens: ', np.mean(n_tok_ret))\n",
    "print('average generated tokens: ', np.mean(n_tok_gen))\n",
    "print('average tokens in info (instructions + transcript): ', np.mean(meeting_tok))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
