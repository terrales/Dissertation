{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e020fd94",
   "metadata": {},
   "source": [
    "# GPT end-to-end with Aveni data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91a0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.9/site-packages (1.13.3)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.9/site-packages (from openai) (3.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.9/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sys import displayhook\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5386aa",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key='') # Insert OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74f5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Following QMSum\n",
    "def tokenize(sent):\n",
    "    tokens = ' '.join(word_tokenize(sent.lower()))\n",
    "    return tokens\n",
    "\n",
    "# filter some noises caused by speech recognition\n",
    "def clean_data(text):\n",
    "    text = text.replace('{ vocalsound }', '')\n",
    "    text = text.replace('{ disfmarker }', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{ pause }', '')\n",
    "    text = text.replace('{ nonvocalsound }', '')\n",
    "    text = text.replace('{ gap }', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05078a25",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52111dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/Aveni/all/annotated_demo_08_11.json\", \"r\") as demo: \n",
    "     demo_queries = json.load(demo)\n",
    "\n",
    "# make lists with queries\n",
    "topic_list = []\n",
    "general_query_list = []\n",
    "specific_query_list = []\n",
    "\n",
    "for i in demo_queries['topic_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"topic\":\n",
    "              topic_list.append(val)\n",
    "for i in demo_queries['general_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              general_query_list.append(val)\n",
    "for i in demo_queries['specific_query_list']:\n",
    "    for key, val in i.items():\n",
    "        if key == \"query\":\n",
    "              specific_query_list.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a65920",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Aveni/all/annotated_demo_08_11.json', 'r') as file:\n",
    "    meeting_transcript = json.load(file)\n",
    "    \n",
    "text = []\n",
    "for turn in meeting_transcript['meeting_transcripts']:\n",
    "    cur_turn = turn['speaker'].lower() + ': '\n",
    "    text.append(clean_data(' '.join(word_tokenize(cur_turn + turn['content'].lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c05014",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07406b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = f\"\"\"You're the assistant for a financial advisor. Use the below meeting transcript to answer all questions. If the answer cannot be found, write \"n/a\"\n",
    "\n",
    "Transcript:\n",
    "\\\"\\\"\\\"\n",
    "{text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244fecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(info, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac21a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str,\n",
    "    print_message: bool = False) -> str:\n",
    "    #message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": info},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edad14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_answers = []\n",
    "for question in general_query_list:\n",
    "    response = ask(question)\n",
    "    general_answers.append(tokenize(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fdc72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_answers = []\n",
    "for question in specific_query_list:\n",
    "    response = ask(question)\n",
    "    specific_answers.append(tokenize(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce22bc7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cb10b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Aveni/all/annotated_demo_08_11.json') as refs:\n",
    "    refs_data = json.load(refs)\n",
    "\n",
    "ref_list = []\n",
    "for i in refs_data['general_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))\n",
    "for i in refs_data['specific_query_list']:\n",
    "        for key, val in i.items():\n",
    "            if key == \"answer\": \n",
    "                ref_list.append(tokenize(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8728891",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_list = general_answers+specific_answers\n",
    "assert len(hyp_list) == len(ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d8109",
   "metadata": {},
   "source": [
    "Summary evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "525efaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.43126451081695266,\n",
      "             'p': 0.4151616191643133,\n",
      "             'r': 0.5051289982384921},\n",
      " 'rouge-2': {'f': 0.17492208661575478,\n",
      "             'p': 0.1652444655168414,\n",
      "             'r': 0.22130857565430687},\n",
      " 'rouge-l': {'f': 0.3994800070826092,\n",
      "             'p': 0.3848458488109418,\n",
      "             'r': 0.46941587001025675}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "for i in range(len(hyp_list)):\n",
    "    data.append({'hyp': hyp_list[i], 'ref': ref_list[i]})\n",
    "\n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "avg_scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "\n",
    "pprint(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b850234",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_data.txt', 'w') as f:\n",
    "    for line in data:\n",
    "        f.write(f\"{line}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13958f5",
   "metadata": {},
   "source": [
    "Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "569dfcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average generated tokens GPT:  98.975\n"
     ]
    }
   ],
   "source": [
    "gen_tok = []\n",
    "for hyp in hyp_list:\n",
    "    gen_tok.append(num_tokens_from_string(hyp, \"cl100k_base\"))\n",
    "    \n",
    "print('average generated tokens GPT: ', np.mean(gen_tok))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
